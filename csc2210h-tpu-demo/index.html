<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>TPU Architecture â€” Interactive Demo</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <!-- ============ Header ============ -->
  <header class="header">
    <h1><span>TPU</span> Architecture Explorer</h1>
    <span class="subtitle">Jouppi et al., ISCA '17 &mdash; In-Datacenter Performance Analysis of a Tensor Processing Unit</span>
    <div class="header-actions">
      <button class="present-btn" id="btnPresent" title="Enter presentation mode (arrow keys to navigate)">Present</button>
    </div>
  </header>

  <!-- ============ Tab Bar ============ -->
  <nav class="tabs" id="tabBar">
    <button class="tab-btn active" data-tab="arch">00 &mdash; Architecture</button>
    <button class="tab-btn" data-tab="systolic">01 &mdash; Systolic Array</button>
    <button class="tab-btn" data-tab="roofline">02 &mdash; Roofline Model</button>
    <button class="tab-btn" data-tab="performance">03 &mdash; Performance</button>
  </nav>

  <!-- ============ Panels ============ -->
  <main class="panel-container">

    <!-- ---- Panel 0: Architecture ---- -->
    <section class="panel active" id="panel-arch">
      <div class="panel-header">
        <h2>TPU &mdash; High-Level Chip Architecture</h2>
        <p>
          The TPU is a <strong>domain-specific ASIC</strong> designed in just 15 months. It strips away the
          complexity of general-purpose processors &mdash; no caches, no branch prediction, no out-of-order
          execution &mdash; and dedicates the silicon to a massive systolic array and on-chip buffers.
          <strong>Hover</strong> (or tap) any block to see what it does and how it compares to CPU/GPU.
        </p>
      </div>

      <div class="card arch-diagram-card" style="padding:1.5rem; overflow:visible;">
        <div class="arch-diagram" id="archDiagram">

          <!-- Row 1: DDR3 DRAM -->
          <div class="arch-block arch-io" id="arch-dram" style="grid-area:dram;">
            DDR3 DRAM<br><small>8 GiB</small>
          </div>

          <!-- Row 2 -->
          <div class="arch-block arch-io" id="arch-ddr" style="grid-area:ddr;">
            DDR3-2133<br>Interface
          </div>
          <div class="arch-block arch-buffer" id="arch-wfifo" style="grid-area:wfifo;">
            Weight FIFO<br><small>(Weight Fetcher)</small>
          </div>

          <!-- Row 3: main data path -->
          <div class="arch-block arch-io" id="arch-pcie" style="grid-area:pcie;">
            PCIe Gen3<br>&times;16
          </div>
          <div class="arch-block arch-buffer" id="arch-host" style="grid-area:host;">
            Host<br>Interface
          </div>
          <div class="arch-block arch-buffer arch-block-large" id="arch-ubuf" style="grid-area:ubuf;">
            Unified Buffer<br><small>24 MiB activation storage</small>
          </div>
          <div class="arch-block arch-buffer" id="arch-setup" style="grid-area:setup;">
            Systolic<br>Data Setup
          </div>
          <div class="arch-block arch-compute arch-block-large" id="arch-mmu" style="grid-area:mmu;">
            Matrix Multiply<br>Unit<br><small>256&times;256 &middot; 64K MACs/cycle</small>
          </div>

          <!-- Row 4 -->
          <div class="arch-block arch-compute" id="arch-acc" style="grid-area:acc;">
            Accumulators<br><small>4 MiB</small>
          </div>

          <!-- Row 5 -->
          <div class="arch-block arch-ctrl" id="arch-ctrl" style="grid-area:ctrl;">
            Control
          </div>
          <div class="arch-block arch-compute" id="arch-act" style="grid-area:act;">
            Activation
          </div>

          <!-- Row 6 -->
          <div class="arch-block arch-ctrl" id="arch-instr" style="grid-area:instr;">
            Instr
          </div>
          <div class="arch-block arch-compute" id="arch-norm" style="grid-area:norm;">
            Normalize / Pool
          </div>

          <!-- Bandwidth arrows (CSS-styled) -->
          <div class="arch-arrow arch-arrow-v" style="grid-area:a1;">30 GiB/s</div>
          <div class="arch-arrow arch-arrow-h" style="grid-area:a2;">30 GiB/s</div>
          <div class="arch-arrow arch-arrow-h" style="grid-area:a3;">14 GiB/s</div>
          <div class="arch-arrow arch-arrow-h" style="grid-area:a4;">14 GiB/s</div>
          <div class="arch-arrow arch-arrow-h" style="grid-area:a5;">167 GiB/s</div>
          <div class="arch-arrow arch-arrow-v" style="grid-area:a6;">30 GiB/s</div>
        </div>

        <!-- Tooltip container -->
        <div class="arch-tip" id="archTip"></div>

        <!-- Legend -->
        <div class="arch-legend">
          <span class="arch-leg-item"><span class="arch-leg-sw arch-leg-io"></span> Off-Chip I/O</span>
          <span class="arch-leg-item"><span class="arch-leg-sw arch-leg-buf"></span> Data Buffer</span>
          <span class="arch-leg-item"><span class="arch-leg-sw arch-leg-comp"></span> Computation</span>
          <span class="arch-leg-item"><span class="arch-leg-sw arch-leg-ctrl"></span> Control</span>
        </div>
      </div>

      <!-- Pipeline Animation Card -->
      <div class="card" id="pipelineCard" style="padding:1.5rem;">
        <div class="card-title">Fused Pipeline &mdash; No Memory Round-Trips</div>
        <p class="card-desc">
          After the systolic array, results flow through Accumulators &rarr; Activation &rarr; Normalize/Pool
          <strong>in hardware, with zero memory writes between stages</strong>. CPUs must launch separate kernels
          for each operation, writing results to memory in between. Watch how pipelining lets multiple layers
          overlap &mdash; completing 4 layers in 7 cycles vs 20.
        </p>
        <div class="controls" id="pipelineControls">
          <button class="primary" id="btnPipePlay">Play</button>
          <button id="btnPipeStep">Step</button>
          <button id="btnPipeReset">Reset</button>
          <label>Speed <input type="range" id="pipeSpeedSlider" min="1" max="10" value="4"></label>
          <span class="cycle-display">Cycle: <span id="pipeCycleNum">0</span></span>
        </div>
        <canvas id="canvasPipeline" width="800" height="300"></canvas>
      </div>

      <div class="insight">
        <strong>Key insight:</strong> The TPU dedicates <strong>67% of die area to compute</strong> and just
        <strong>2% to control</strong>. CPUs spend &sim;25% on control (branch prediction, OoO execution).
        By dropping all general-purpose complexity, the TPU fits <strong>25&times; more MACs</strong> in half the die area.
      </div>
    </section>

    <!-- ---- Panel 1: Systolic Array ---- -->
    <section class="panel" id="panel-systolic">
      <div class="panel-header">
        <h2>Systolic Array &mdash; How the TPU Multiplies Matrices</h2>
        <p>
          The TPU's 256&times;256 matrix multiply unit uses a <strong>systolic array</strong> &mdash; data flows
          left-to-right while pre-loaded weights sit in each cell. Partial sums accumulate downward as a
          diagonal wavefront. Compare this with a CPU, which must repeatedly fetch the same data from memory.
        </p>
      </div>

      <div class="controls" id="systolicControls">
        <button class="primary" id="btnPlayPause">Play</button>
        <button id="btnStep">Step</button>
        <button id="btnReset">Reset</button>
        <label>Speed <input type="range" id="speedSlider" min="1" max="10" value="4"></label>
        <span class="cycle-display">Cycle: <span id="cycleNum">0</span></span>
      </div>

      <div class="systolic-layout">
        <div class="card">
          <div class="card-title">TPU &mdash; Systolic Data Flow</div>
          <canvas id="canvasSystolic" width="560" height="560"></canvas>
          <div class="stat-row">
            <span class="stat-badge">Mem reads: <span class="val" id="tpuReads">0</span></span>
            <span class="stat-badge">MACs: <span class="val" id="tpuMacs">0</span></span>
          </div>
        </div>
        <div class="card">
          <div class="card-title">CPU &mdash; Sequential Dot Products</div>
          <canvas id="canvasCPU" width="560" height="560"></canvas>
          <div class="stat-row">
            <span class="stat-badge">Mem reads: <span class="val" id="cpuReads">0</span></span>
            <span class="stat-badge">MACs: <span class="val" id="cpuMacs">0</span></span>
          </div>
        </div>
      </div>

      <div class="insight">
        <strong>Key insight:</strong> For an N&times;N multiply, the CPU needs O(N&sup3;) memory reads.
        The systolic array needs only O(N&sup2;) &mdash; each value is loaded once and reused spatially.
        This is why the TPU packs <strong>65,536 MACs</strong> on a die half the size of the GPU.
      </div>
    </section>

    <!-- ---- Panel 2: Roofline ---- -->
    <section class="panel" id="panel-roofline">
      <div class="panel-header">
        <h2>Roofline Model &mdash; Why the TPU Wins</h2>
        <p>
          The Roofline model plots attainable performance (TOPS) against operational intensity
          (ops / byte of weight memory). Applications below the roofline ceiling are either
          <strong>memory-bound</strong> (under the slant) or <strong>compute-bound</strong> (under the flat).
        </p>
      </div>

      <div class="card roofline-wrapper">
        <div class="roofline-controls" id="rooflineControls">
          <label class="chip-toggle">
            <input type="checkbox" id="togCPU" checked>
            <span class="chip-swatch" style="background:#607d8b"></span> Haswell CPU
          </label>
          <label class="chip-toggle">
            <input type="checkbox" id="togGPU" checked>
            <span class="chip-swatch" style="background:#2e7d32"></span> K80 GPU
          </label>
          <label class="chip-toggle">
            <input type="checkbox" id="togTPU" checked>
            <span class="chip-swatch" style="background:#c94a1a"></span> TPU
          </label>
          <span style="color:var(--text-muted); font-size:0.72rem; margin-left:0.6rem; font-family:var(--font-mono);">|</span>
          <label style="font-family:var(--font-mono); font-size:0.72rem; color:var(--text-muted); display:flex; align-items:center; gap:0.4rem; text-transform:uppercase; letter-spacing:0.04em;">
            TPU Mem BW
            <input type="range" id="memBwSlider" min="34" max="200" value="34" step="1" style="width:150px; accent-color:var(--accent-burn);">
            <span class="slider-val" id="memBwVal">34 GB/s</span>
          </label>
        </div>
        <div id="rooflineChart"></div>
        <div class="tooltip" id="rooflineTip"></div>
      </div>

      <div class="insight">
        <strong>Key insight:</strong> 4 of 6 apps are <strong>memory-bound</strong> on the TPU, not compute-bound.
        Drag the memory bandwidth slider to 170 GB/s (GDDR5) to see TPU' &mdash; performance <strong>triples</strong>
        for memory-bound workloads, shifting the ridge point from 1350 to ~250 ops/byte.
      </div>
    </section>

    <!-- ---- Panel 3: Performance ---- -->
    <section class="panel" id="panel-performance">
      <div class="panel-header">
        <h2>Performance &amp; Efficiency &mdash; The Results</h2>
        <p>
          The TPU is 15&ndash;30&times; faster than contemporary CPUs and GPUs for inference,
          with 30&ndash;80&times; better performance per watt &mdash; and it gets <em>better</em> under
          strict latency constraints.
        </p>
      </div>

      <div class="perf-grid">
        <div class="card">
          <div class="card-title">Relative Performance per Die (vs CPU = 1&times;)</div>
          <p class="card-desc">How many times faster each chip is compared to the Haswell CPU baseline. Geo-mean averages across all six NN workloads; weighted mean reflects actual datacenter traffic mix.</p>
          <div id="perfBarChart"></div>
          <div class="legend" id="perfLegend"></div>
        </div>
        <div class="card">
          <div class="card-title">Performance / Watt (relative to CPU server)</div>
          <p class="card-desc">Throughput normalized by total system power (TDP). Higher = more efficient. This is the metric that justified building a custom ASIC &mdash; power is the dominant cost in datacenters.</p>
          <div id="perfWattChart"></div>
          <div class="legend" id="wattLegend"></div>
        </div>
        <div class="card">
          <div class="card-title">Die Area Breakdown</div>
          <p class="card-desc">How each chip allocates its silicon. The TPU dedicates 67% to compute datapath vs ~24% for CPU/GPU. Minimal control logic means more room for MAC units.</p>
          <div id="dieAreaChart" style="display:flex; gap:1rem; justify-content:center; flex-wrap:wrap;"></div>
        </div>
        <div class="card">
          <div class="card-title">Latency vs Throughput (MLP0, 7&thinsp;ms deadline)</div>
          <p class="card-desc">Tighter latency deadlines force smaller batch sizes, reducing throughput. The TPU&rsquo;s deterministic execution retains more throughput under strict deadlines than CPU or GPU.</p>
          <div id="latencyChart"></div>
          <div class="controls" style="margin-top:0.6rem;">
            <label>
              Latency deadline
              <input type="range" id="latencySlider" min="5" max="25" value="7" step="0.5" style="width:150px; accent-color:var(--accent-burn);">
              <span class="slider-val" id="latencyVal">7.0 ms</span>
            </label>
          </div>
        </div>
      </div>

      <div class="insight">
        <strong>Key insight:</strong> The TPU's deterministic, single-threaded execution model is a
        better match for <strong>99th-percentile latency</strong> than the time-varying optimizations
        of CPUs and GPUs. Under a 7 ms deadline, the TPU retains 80% of peak throughput while the
        CPU and GPU drop to 42% and 37%.
      </div>
    </section>

  </main>

  <!-- ============ Scripts ============ -->
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <script src="data.js"></script>
  <script src="systolic.js"></script>
  <script src="roofline.js"></script>
  <script src="performance.js"></script>
  <script src="pipeline.js"></script>
  <script src="arch.js"></script>
  <script src="present.js"></script>
  <script>
    // ---- Tab switching ----
    function switchTab(tabName) {
      document.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('active'));
      document.querySelectorAll('.panel').forEach(p => p.classList.remove('active'));
      const btn = document.querySelector(`.tab-btn[data-tab="${tabName}"]`);
      if (btn) btn.classList.add('active');
      document.getElementById('panel-' + tabName).classList.add('active');
      window.dispatchEvent(new Event('resize'));
    }
    document.querySelectorAll('.tab-btn').forEach(btn => {
      btn.addEventListener('click', () => switchTab(btn.dataset.tab));
    });
  </script>
</body>
</html>
